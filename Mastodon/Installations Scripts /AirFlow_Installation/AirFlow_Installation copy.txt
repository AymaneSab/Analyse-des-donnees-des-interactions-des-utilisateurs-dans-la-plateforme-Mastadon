######################################################################################################################################################################################################
											        AirFlow 
######################################################################################################################################################################################################





######################################################################################################################################################################################################
											AirFlow Installation 
######################################################################################################################################################################################################



######################################################################
                             Requirment  		  	     # 
######################################################################

---- > Download conda 
---- > make virtual environment with Python

# cd /home/hadoop 
# mkdir AirFlow
# cd /home/hadoop/AirFlow
# mkdir airflow-environment
# cd /home/hadoop/AirFlow/airflow-environment

# conda create --name airflow-environment python=3.9
# conda activate airflow-environment

# export AIRFLOW_HOME = pwd ( Absolut path of the working directory )
# export AIRFLOW_HOME="/home/hadoop/AirFlow/airflow-environment"





######################################################################
                             AirFlow Configuration   	 	     # 
######################################################################

# export AIRFLOW_HOME=/home/hadoop/AirFlow/airflow-environment



######################################################################
                             Install dependencies   	 	     # 
######################################################################

# sudo apt-get update && sudo apt-get install -y
# sudo apt-get install python-setuptools
# sudo apt-get install python3-pip
# sudo apt-get install python3-dev
# sudo apt-get install libffi-dev
# sudo apt-get install zip
# sudo apt-get install wget
# sudo apt-get install install gcc python3-dev
# sudo apt-get install pkg-config libxml2-dev libxmlsec1-dev libxmlsec1-openssl
# sudo apt-get install libcairo2-dev
# sudo apt-get install libdbus-1-dev
# sudo apt-get install libgirepository1.0-dev

# pip install apache-airflow
# pip install gcp
# pip install statsd
# pip install sentry
# pip install cryptography
# pip install pyspark
# pip install connexion



######################################################################
                             First Run   	 	             # 
######################################################################


# cd /home/hadoop/AirFlow
# conda activate airflow-environment

# export AIRFLOW_HOME=/home/hadoop/AirFlow/airflow-environment
# airflow db init
# airflow users create --role Admin --username admin --email admin --firstname admin --lastname admin --password AllahSave.1234/



######################################################################################################################################################################################################
											Apache Airflow on Linux Ubuntu - Start
######################################################################################################################################################################################################


######################################################################
                    First Terminal - Airflow webserver               # 
######################################################################


# cd /home/hadoop/AirFlow/airflow-environment
# conda activate airflow-environment
# export AIRFLOW_HOME=/home/hadoop/AirFlow/airflow-environment
# airflow db init
# airflow webserver -p 8080




######################################################################
                    Second Terminal - Airflow scheduler              # 
######################################################################


# cd /home/hadoop/AirFlow/airflow-environment
# conda activate airflow-environment
# export AIRFLOW_HOME=/home/hadoop/AirFlow/airflow-environment
# airflow db init
# airflow scheduler


######################################################################
                    stop airflow webserver             		     # 
######################################################################



---- > find the process id: (assuming 8080 is the port)

# lsof -i tcp:8080

---- > kill it

# kill <pid>







