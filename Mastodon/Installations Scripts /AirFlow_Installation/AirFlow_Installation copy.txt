######################################################################################################################################################################################################
											        AirFlow 
######################################################################################################################################################################################################





######################################################################################################################################################################################################
											AirFlow Installation 
######################################################################################################################################################################################################



######################################################################
                             Requirment  		  	     # 
######################################################################

---- > Download conda 
---- > make virtual environment with Python

# cd /home/hadoop 
# mkdir AirFlow
# cd /home/hadoop/AirFlow
# mkdir airflow-environment
# cd /home/hadoop/AirFlow/airflow-environment

# conda create --name airflow-environment python = 3.9
# conda activate airflow-environment

# export AIRFLOW_HOME = pwd ( Absolut path of the working directory )




######################################################################
                             AirFlow Configuration   	 	     # 
######################################################################

# export AIRFLOW_HOME=/home/hadoop/AirFlow/airflow-environment



######################################################################
                             Install dependencies   	 	     # 
######################################################################

# sudo apt-get update && sudo apt-get install -y
# sudo apt-get python-setuptools
# sudo apt-get python3-pip
# sudo apt-get python-dev
# sudo apt-get libffi-dev
# sudo apt-get zip
# sudo apt-get wget
# sudo apt-get install gcc python3-dev
# sudo apt-get install pkg-config libxml2-dev libxmlsec1-dev libxmlsec1-openssl

# pip install apache-airflow
# pip install gcp
# pip install statsd
# pip install sentry==2.1.2
# pip install cryptography
# pip install pyspark


######################################################################
                             First Run   	 	             # 
######################################################################


# cd /home/hadoop/AirFlow
# conda activate airflow-environment

# export AIRFLOW_HOME = /home/hadoop/AirFlow/airflow-environment
# airflow db init
# airflow users create --role Admin --username admin --email admin --firstname admin --lastname admin --password AllahSave.1234/



######################################################################################################################################################################################################
											Apache Airflow on Linux Ubuntu - Start
######################################################################################################################################################################################################


######################################################################
                    First Terminal - Airflow webserver               # 
######################################################################


# cd /home/hadoop/AirFlow/airflow-environment
# conda activate airflow-environment
# export AIRFLOW_HOME=/home/hadoop/AirFlow/airflow-environment
# airflow db init
# airflow webserver -p 8080




######################################################################
                    Second Terminal - Airflow scheduler              # 
######################################################################


# cd /home/hadoop/AirFlow/airflow-environment
# conda activate airflow-environment
# export AIRFLOW_HOME=/home/hadoop/AirFlow/airflow-environment
# airflow db init
# airflow scheduler


######################################################################
                    stop airflow webserver             		     # 
######################################################################



---- > find the process id: (assuming 8080 is the port)

# lsof -i tcp:8080

---- > kill it

# kill <pid>







